https://repo.anaconda.com/miniconda/

https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

https://alphacephei.com/vosk/

ffmpeg install


pip install vosk



vosk-transcriber  --input v.mp4 --output s.srt --output-type srt


usage 


 vosk-transcriber  -h
usage: vosk-transcriber [-h] [--model MODEL] [--server] [--list-models] [--list-languages]
                        [--model-name MODEL_NAME] [--lang LANG] [--input INPUT] [--output OUTPUT]
                        [--output-type OUTPUT_TYPE] [--tasks TASKS] [--log-level LOG_LEVEL]

Transcribe audio file and save result in selected format

options:
  -h, --help            show this help message and exit
  --model MODEL, -m MODEL
                        model path
  --server, -s          use server for recognition
  --list-models         list available models
  --list-languages      list available languages
  --model-name MODEL_NAME, -n MODEL_NAME
                        select model by name
  --lang LANG, -l LANG  select model by language
  --input INPUT, -i INPUT
                        audiofile
  --output OUTPUT, -o OUTPUT
                        optional output filename path
  --output-type OUTPUT_TYPE, -t OUTPUT_TYPE
                        optional arg output data type
  --tasks TASKS, -ts TASKS
                        number of parallel recognition tasks
  --log-level LOG_LEVEL
                        logging level


https://alphacephei.com/vosk/models

cd ~/.cache/vosk/

https://alphacephei.com/vosk/models/vosk-model-en-us-0.22-lgraph.zip

7zz x vosk-model-en-us-0.22-lgraph.zip

vosk-transcriber  -m ~/.cache/vosk/vosk-model-en-us-0.22-lgraph -i input.mp4 -t srt -o input.srt
